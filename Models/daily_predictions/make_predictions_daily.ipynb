{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading different models\n",
    "close_model=load_model('built_models/predict_next_day_close.h5')\n",
    "# open_model=load_model('built_models/predict_next_day_open.h5')\n",
    "# high_model=load_model('built_models/predict_next_day_high.h5')\n",
    "# low_model=load_model('built_models/predict_next_day_low.h5')\n",
    "# volume_model=load_model('built_models/predict_next_day_volume.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../spy_current_daily.csv does not exist: '../spy_current_daily.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-667f5c2f0076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../spy_current_daily.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"1. open\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2. high\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"high\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"3. low\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"4. close\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"5. volume\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"volume\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../spy_current_daily.csv does not exist: '../spy_current_daily.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"../spy_current_daily.csv\")\n",
    "data.rename(columns={\"1. open\":\"open\",\"2. high\":\"high\",\"3. low\":\"low\",\"4. close\":\"close\",\"5. volume\":\"volume\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the dataset\n",
    "data = data[::-1].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>353.49</td>\n",
       "      <td>355.1800</td>\n",
       "      <td>350.51</td>\n",
       "      <td>354.04</td>\n",
       "      <td>85552022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>356.40</td>\n",
       "      <td>357.5600</td>\n",
       "      <td>355.06</td>\n",
       "      <td>356.67</td>\n",
       "      <td>58649048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>355.58</td>\n",
       "      <td>356.7182</td>\n",
       "      <td>351.26</td>\n",
       "      <td>353.21</td>\n",
       "      <td>68118563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>355.27</td>\n",
       "      <td>358.9000</td>\n",
       "      <td>354.71</td>\n",
       "      <td>358.10</td>\n",
       "      <td>62959429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>360.98</td>\n",
       "      <td>362.7800</td>\n",
       "      <td>359.59</td>\n",
       "      <td>362.57</td>\n",
       "      <td>72203007.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        open      high     low   close      volume\n",
       "5291  353.49  355.1800  350.51  354.04  85552022.0\n",
       "5292  356.40  357.5600  355.06  356.67  58649048.0\n",
       "5293  355.58  356.7182  351.26  353.21  68118563.0\n",
       "5294  355.27  358.9000  354.71  358.10  62959429.0\n",
       "5295  360.98  362.7800  359.59  362.57  72203007.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(\"date\", axis=1)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of datapoints to use in predictions\n",
    "history_points=50\n",
    "# Scaling data\n",
    "MinMaxScaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating y_scaler for predicted variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriving the real next day open values\n",
    "next_day_close_values = np.array([data.iloc[:,3][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "# next_day_open_values = np.array([data.iloc[:,0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "# next_day_high_values = np.array([data.iloc[:,1][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "# next_day_low_values = np.array([data.iloc[:,2][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "# next_day_volume_values = np.array([data.iloc[:,4][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "# Expanding the dimentions of next_day_open_values_normalised (5246, 1, 1)\n",
    "unscaled_close_y = np.expand_dims(next_day_close_values, -1)\n",
    "# unscaled_open_y = np.expand_dims(next_day_open_values, -1)\n",
    "# unscaled_high_y = np.expand_dims(next_day_high_values, -1)\n",
    "# unscaled_low_y = np.expand_dims(next_day_low_values, -1)\n",
    "# unscaled_volume_y = np.expand_dims(next_day_volume_values, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser_close=y_normaliser.fit(unscaled_close_y)\n",
    "# y_normaliser = preprocessing.MinMaxScaler()\n",
    "# y_normaliser_open=y_normaliser.fit(unscaled_open_y)\n",
    "# y_normaliser = preprocessing.MinMaxScaler()\n",
    "# y_normaliser_high=y_normaliser.fit(unscaled_high_y)\n",
    "# y_normaliser = preprocessing.MinMaxScaler()\n",
    "# y_normaliser_low=y_normaliser.fit(unscaled_low_y)\n",
    "# y_normaliser = preprocessing.MinMaxScaler()\n",
    "# y_normaliser_volume=y_normaliser.fit(unscaled_volume_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict close value\n",
    "def make_prediction(data, model, y_norm):\n",
    "    # Normalize the input data\n",
    "    normalized_data=MinMaxScaler.fit_transform(data[-50:])\n",
    "    # Predict next day's close\n",
    "    today=model.predict(np.expand_dims(normalized_data, 0))\n",
    "    # Convert the close to real terms\n",
    "    last=y_norm.inverse_transform(today)\n",
    "    return float(last[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_actual_values(data, variable_to_predict, model, y_normaliser):    \n",
    "    # make prediction\n",
    "    prediction=make_prediction(data[-50:], model, y_normaliser)\n",
    "    # converting to actual stock market price\n",
    "    last_prediction=make_prediction(data[-51:-1], model, y_normaliser)\n",
    "    # calculating percent change of from last predicted value\n",
    "    prediction_percent_change=((prediction-last_prediction)/last_prediction)\n",
    "    # getting last actual value\n",
    "    last_actual = data[-3:].iloc[2][variable_to_predict]\n",
    "    # calculating predicted percent change on actual value\n",
    "    predicted_actual_close=last_actual+(last_actual*prediction_percent_change)\n",
    "    return float(predicted_actual_close), last_prediction, prediction_percent_change, last_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buy, sell or hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Predicted Close: 337.7259521484375\n",
      "Next Predicted Close: 332.8974304199219\n",
      "Last Actual Close: 362.57\n",
      "Predicted Actual Close: 357.3862789623628\n"
     ]
    }
   ],
   "source": [
    "predicted_close = make_prediction(data, close_model, y_normaliser_close)\n",
    "predicted_actual, last_prediction, percent_change, last_actual = predict_actual_values(data, \"close\", close_model, y_normaliser_close)\n",
    "print(f\"Last Predicted Close: {last_prediction}\")\n",
    "print(f\"Next Predicted Close: {predicted_close}\")\n",
    "print(f\"Last Actual Close: {last_actual}\")\n",
    "print(f\"Predicted Actual Close: {predicted_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade based off *price* predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price Change: -4.828521728515625\n",
      "hold\n"
     ]
    }
   ],
   "source": [
    "buys=[]\n",
    "sells=[]\n",
    "\n",
    "thresh = 5.00\n",
    "diff = predicted_close - last_prediction\n",
    "print(f\"Predicted Price Change: {diff}\")\n",
    "\n",
    "if diff > thresh:\n",
    "    print(\"buy\")\n",
    "elif diff < -thresh:\n",
    "    print(\"sell\")\n",
    "else:\n",
    "    print(\"hold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade based off *percent change* predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Percent Change: -1.429715927307058\n",
      "sell\n"
     ]
    }
   ],
   "source": [
    "thresh = .5\n",
    "change=percent_change*100\n",
    "print(f\"Predicted Percent Change: {change}\")\n",
    "\n",
    "if change > thresh:\n",
    "    print(\"buy\")\n",
    "elif change < -thresh:\n",
    "    print(\"sell\")\n",
    "else:\n",
    "    print(\"hold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_to_predict = 10\n",
    "# index=max(data.index)\n",
    "\n",
    "# for i in range(days_to_predict):\n",
    "#     new_row=pd.DataFrame({\n",
    "#         \"open\":predict_actual_values(data[-50:], \"open\", open_model, y_normaliser_open),\n",
    "#         \"high\":predict_actual_values(data[-50:], \"high\", high_model, y_normaliser_high),\n",
    "#         \"low\":predict_actual_values(data[-50:], \"low\", low_model, y_normaliser_low),\n",
    "#         \"close\":predict_actual_values(data[-50:], \"close\", close_model, y_normaliser_close),\n",
    "#         \"volume\":predict_actual_values(data[-50:], \"volume\", volume_model, y_normaliser_volume)\n",
    "#     }, index=[index+1])\n",
    "#     data=data.append(new_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
