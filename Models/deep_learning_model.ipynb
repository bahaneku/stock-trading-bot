{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "tensorflow.keras.__version__\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock_splits</th>\n",
       "      <th>price_change_$</th>\n",
       "      <th>price_change_%</th>\n",
       "      <th>price_swing</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>volume_change_%</th>\n",
       "      <th>price_change_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>26.098205</td>\n",
       "      <td>26.265144</td>\n",
       "      <td>26.098205</td>\n",
       "      <td>26.265144</td>\n",
       "      <td>480500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185486</td>\n",
       "      <td>0.711228</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>-522700.0</td>\n",
       "      <td>-52.103270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993-02-02</td>\n",
       "      <td>26.246586</td>\n",
       "      <td>26.339331</td>\n",
       "      <td>26.190940</td>\n",
       "      <td>26.320782</td>\n",
       "      <td>201300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.211830</td>\n",
       "      <td>0.148391</td>\n",
       "      <td>-279200.0</td>\n",
       "      <td>-58.106139</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>26.357880</td>\n",
       "      <td>26.617563</td>\n",
       "      <td>26.339331</td>\n",
       "      <td>26.599014</td>\n",
       "      <td>529400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278233</td>\n",
       "      <td>1.057083</td>\n",
       "      <td>0.278232</td>\n",
       "      <td>328100.0</td>\n",
       "      <td>162.990561</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-02-04</td>\n",
       "      <td>26.691763</td>\n",
       "      <td>26.765958</td>\n",
       "      <td>26.394982</td>\n",
       "      <td>26.710312</td>\n",
       "      <td>531500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111298</td>\n",
       "      <td>0.418428</td>\n",
       "      <td>0.370977</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0.396675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-02-05</td>\n",
       "      <td>26.691771</td>\n",
       "      <td>26.747417</td>\n",
       "      <td>26.543380</td>\n",
       "      <td>26.691771</td>\n",
       "      <td>492100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018541</td>\n",
       "      <td>-0.069416</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>-39400.0</td>\n",
       "      <td>-7.412982</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       open       high        low      close  volume  dividends  \\\n",
       "0  1993-02-01  26.098205  26.265144  26.098205  26.265144  480500        0.0   \n",
       "1  1993-02-02  26.246586  26.339331  26.190940  26.320782  201300        0.0   \n",
       "2  1993-02-03  26.357880  26.617563  26.339331  26.599014  529400        0.0   \n",
       "3  1993-02-04  26.691763  26.765958  26.394982  26.710312  531500        0.0   \n",
       "4  1993-02-05  26.691771  26.747417  26.543380  26.691771  492100        0.0   \n",
       "\n",
       "   stock_splits  price_change_$  price_change_%  price_swing  volume_change  \\\n",
       "0             0        0.185486        0.711228     0.166939      -522700.0   \n",
       "1             0        0.055637        0.211830     0.148391      -279200.0   \n",
       "2             0        0.278233        1.057083     0.278232       328100.0   \n",
       "3             0        0.111298        0.418428     0.370977         2100.0   \n",
       "4             0       -0.018541       -0.069416     0.204037       -39400.0   \n",
       "\n",
       "   volume_change_%  price_change_binary  \n",
       "0       -52.103270                  1.0  \n",
       "1       -58.106139                  1.0  \n",
       "2       162.990561                  1.0  \n",
       "3         0.396675                  1.0  \n",
       "4        -7.412982                  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../Data/stock_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"close\", \"volume_change_%\"]]\n",
    "y=df[[\"price_change_binary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use when units and scale are the same\n",
    "# X_scaler = MinMaxScaler().fit(X_train)\n",
    "# y_scaler = MinMaxScaler().fit(y_train)\n",
    "\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "# y_train_scaled = y_scaler.transform(y_train)\n",
    "# y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use when units are different\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=len(X.columns)))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 10,602\n",
      "Trainable params: 10,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "165/165 - 0s - loss: 0.6828 - accuracy: 0.5524\n",
      "Epoch 2/50\n",
      "165/165 - 0s - loss: 0.6738 - accuracy: 0.5823\n",
      "Epoch 3/50\n",
      "165/165 - 0s - loss: 0.6715 - accuracy: 0.5876\n",
      "Epoch 4/50\n",
      "165/165 - 0s - loss: 0.6701 - accuracy: 0.5848\n",
      "Epoch 5/50\n",
      "165/165 - 0s - loss: 0.6698 - accuracy: 0.5836\n",
      "Epoch 6/50\n",
      "165/165 - 0s - loss: 0.6687 - accuracy: 0.5884\n",
      "Epoch 7/50\n",
      "165/165 - 0s - loss: 0.6695 - accuracy: 0.5895\n",
      "Epoch 8/50\n",
      "165/165 - 0s - loss: 0.6685 - accuracy: 0.5893\n",
      "Epoch 9/50\n",
      "165/165 - 0s - loss: 0.6683 - accuracy: 0.5840\n",
      "Epoch 10/50\n",
      "165/165 - 0s - loss: 0.6689 - accuracy: 0.5884\n",
      "Epoch 11/50\n",
      "165/165 - 0s - loss: 0.6675 - accuracy: 0.5918\n",
      "Epoch 12/50\n",
      "165/165 - 0s - loss: 0.6682 - accuracy: 0.5891\n",
      "Epoch 13/50\n",
      "165/165 - 0s - loss: 0.6675 - accuracy: 0.5880\n",
      "Epoch 14/50\n",
      "165/165 - 0s - loss: 0.6676 - accuracy: 0.5897\n",
      "Epoch 15/50\n",
      "165/165 - 0s - loss: 0.6675 - accuracy: 0.5891\n",
      "Epoch 16/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5901\n",
      "Epoch 17/50\n",
      "165/165 - 0s - loss: 0.6681 - accuracy: 0.5899\n",
      "Epoch 18/50\n",
      "165/165 - 0s - loss: 0.6677 - accuracy: 0.5907\n",
      "Epoch 19/50\n",
      "165/165 - 0s - loss: 0.6689 - accuracy: 0.5876\n",
      "Epoch 20/50\n",
      "165/165 - 0s - loss: 0.6677 - accuracy: 0.5903\n",
      "Epoch 21/50\n",
      "165/165 - 0s - loss: 0.6681 - accuracy: 0.5872\n",
      "Epoch 22/50\n",
      "165/165 - 0s - loss: 0.6677 - accuracy: 0.5878\n",
      "Epoch 23/50\n",
      "165/165 - 0s - loss: 0.6672 - accuracy: 0.5859\n",
      "Epoch 24/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5895\n",
      "Epoch 25/50\n",
      "165/165 - 0s - loss: 0.6682 - accuracy: 0.5855\n",
      "Epoch 26/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5909\n",
      "Epoch 27/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5893\n",
      "Epoch 28/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5886\n",
      "Epoch 29/50\n",
      "165/165 - 0s - loss: 0.6670 - accuracy: 0.5880\n",
      "Epoch 30/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5855\n",
      "Epoch 31/50\n",
      "165/165 - 0s - loss: 0.6669 - accuracy: 0.5890\n",
      "Epoch 32/50\n",
      "165/165 - 0s - loss: 0.6669 - accuracy: 0.5876\n",
      "Epoch 33/50\n",
      "165/165 - 0s - loss: 0.6666 - accuracy: 0.5920\n",
      "Epoch 34/50\n",
      "165/165 - 0s - loss: 0.6673 - accuracy: 0.5907\n",
      "Epoch 35/50\n",
      "165/165 - 0s - loss: 0.6668 - accuracy: 0.5884\n",
      "Epoch 36/50\n",
      "165/165 - 0s - loss: 0.6667 - accuracy: 0.5886\n",
      "Epoch 37/50\n",
      "165/165 - 0s - loss: 0.6666 - accuracy: 0.5907\n",
      "Epoch 38/50\n",
      "165/165 - 0s - loss: 0.6672 - accuracy: 0.5855\n",
      "Epoch 39/50\n",
      "165/165 - 0s - loss: 0.6661 - accuracy: 0.5882\n",
      "Epoch 40/50\n",
      "165/165 - 0s - loss: 0.6668 - accuracy: 0.5897\n",
      "Epoch 41/50\n",
      "165/165 - 0s - loss: 0.6671 - accuracy: 0.5886\n",
      "Epoch 42/50\n",
      "165/165 - 0s - loss: 0.6666 - accuracy: 0.5882\n",
      "Epoch 43/50\n",
      "165/165 - 0s - loss: 0.6664 - accuracy: 0.5912\n",
      "Epoch 44/50\n",
      "165/165 - 0s - loss: 0.6664 - accuracy: 0.5888\n",
      "Epoch 45/50\n",
      "165/165 - 0s - loss: 0.6660 - accuracy: 0.5910\n",
      "Epoch 46/50\n",
      "165/165 - 0s - loss: 0.6668 - accuracy: 0.5870\n",
      "Epoch 47/50\n",
      "165/165 - 0s - loss: 0.6665 - accuracy: 0.5918\n",
      "Epoch 48/50\n",
      "165/165 - 0s - loss: 0.6660 - accuracy: 0.5931\n",
      "Epoch 49/50\n",
      "165/165 - 0s - loss: 0.6661 - accuracy: 0.5901\n",
      "Epoch 50/50\n",
      "165/165 - 0s - loss: 0.6663 - accuracy: 0.5907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5ef2a0250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.6780 - accuracy: 0.5691\n",
      "Normal Neural Network - Loss: 0.6779671311378479, Accuracy: 0.5691428780555725\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
